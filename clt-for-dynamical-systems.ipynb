{
cells: [
{
cell_type: "markdown",
metadata: { },
source: [
"# Programming Exercise 1: Donsker's invariance principle ",
" ",
"From time to time there will be little programming exercises as part of the homework. They will all be set up in online notebooks like this and you do not have to install anything. We use Python, which with its Numpy and Matplotlib packages is a very powerful tool for mathematical simulations and which also is the standard programming language in data science. To get started with Python and Numpy, you can have a look at ",
" ",
"https://docs.scipy.org/doc/numpy/user/quickstart.html ",
"or ",
"https://docs.python.org/3/tutorial/ ",
" ",
"But there are many great online resources, also Youtube might be helpful. As a general rule the programming exercises will only require a few lines of code, so there is no need to dive deep into the details of Python. ",
" ",
"Once you have completed the task, please save your solution under "File->Download as->Notebook (.ipynb)" and upload the resulting file via the FU Whiteboard system. ",
" ",
"First let us import the libraries that we will need. The option "%matplotlib inline" is supposed to make Matplotlib work better with our notebook."
]
},
{
cell_type: "code",
execution_count: 3,
metadata: { },
outputs: [ ],
source: [
"%matplotlib inline ",
"import numpy as np ",
"from matplotlib import pyplot as plt"
]
},
{
cell_type: "markdown",
metadata: { },
source: [
"To give you an example that can serve as inspiration, we first simulate and plot the sine and the cosine functions:"
]
},
{
cell_type: "code",
execution_count: 7,
metadata: { },
outputs: [ ],
source: [
"time = np.arange(0,4*np.pi,0.1) ",
"sine = np.sin(time) ",
" ",
"plt.plot(time,sine) ",
"plt.show() ",
" ",
"cosine = np.cos(time) ",
"plt.plot(time,cosine) ",
"plt.show()"
]
},
{
cell_type: "markdown",
metadata: { },
source: [
"Now let's start with the exercise: Choose your favorite probability distribution from ",
"https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.random.html ",
"and make sure that it has expectation 0 and variance 1 (either by choosing the right parameter or by rescaling it). Let $(X_k)_{k \in \mathbb N}$ be an i.i.d. sequence of random variables with your distribution. Plot the process $(S^n_t)_{t \in [0,1]}$ from Section 2.2 of the lecture notes for $n=20, 100, 1000, 10000$. ",
" ",
"Hint: https://docs.scipy.org/doc/numpy/reference/generated/numpy.cumsum.html"
]
},
{
cell_type: "code",
execution_count: 3,
metadata: { },
outputs: [ ],
source: [
"#TODO: your implementation goes here. ",
"#For example x = np.random.rand(100) would generate a vector of 100 independent ",
"#random variables that are uniformly distributed on [0,1]."
]
},
{
cell_type: "markdown",
metadata: { },
source: [
"Now simulate a Brownian motion $(B_t)_{t \in [0,1]}$ with a step size of 0.001 and plot it. ",
" ",
"(Hint: how are the increments $(B_{0.001} - B_0, B_{0.002}-B_{0.001}, \dots, B_1 - B_{0.999})$ distributed?)"
]
},
{
cell_type: "code",
execution_count: 6,
metadata: { },
outputs: [ ],
source: [
"#TODO: your implementation goes here."
]
},
{
cell_type: "markdown",
metadata: { },
source: [
"Next, simulate the running maximum of the rescaled random walk with $n=10000$ and plot it: ",
"$$ ",
" M^n_t = max_{s \in [0,t]} S^n_s. ",
"$$"
]
},
{
cell_type: "code",
execution_count: 28,
metadata: { },
outputs: [ ],
source: [
"#TODO: your implementation goes here."
]
},
{
cell_type: "markdown",
metadata: { },
source: [
"This suggests that "on large scales all random walks look like a Brownian motion". All? Well notentirely! One small group of indomitable random walks still holds outagainst the attraction of Brownian motion: Simulate $(S^n_t)_{t \in [0,1]}$ for an i.i.d. sequence of $(X_k)_{k \in \mathbb N}$ of Cauchy random variables (np.random.standard_cauchy) and $n=10000$. This should look very differently from the previous simulations. Can you find out why? ",
" ",
"(Hint: https://en.wikipedia.org/wiki/Cauchy_distribution)"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"#TODO: your implementation goes here."
]
},
{
cell_type: "markdown",
metadata: { },
source: [
"This last part of the exercise is voluntary. Our aim is to create a movie that illustrates Donsker's invariance principle. This short tutorial explains very well how to create simple movies: https://jakevdp.github.io/blog/2012/08/18/matplotlib-animation-tutorial/, see also http://louistiao.me/posts/notebooks/embedding-matplotlib-animations-in-jupyter-notebooks/ for an adaptation that displays the movie directly in our notebook. ",
" ",
"The following code is a slight adaptation from these tutorials and might also serve as inspiration:"
]
},
{
cell_type: "code",
execution_count: 5,
metadata: {
scrolled: true
},
outputs: [ ],
source: [
"from matplotlib import animation, rc ",
"from IPython.display import HTML ",
" ",
"# First set up the figure, the axis, and the plot element we want to animate: ",
"fig, ax = plt.subplots() ",
"# We want the axis to scale automatically. ",
"ax.set_autoscale_on(True) ",
"line, = ax.plot([], [], lw=2) ",
" ",
" ",
"# initialization function: Plot the background of each frame. ",
"def init(): ",
" line.set_data([], []) ",
" return (line,) ",
" ",
"# animation function. This is called sequentially in i. ",
"# In the i-th step we simulate the function x*sin(x^(0.8)) for x in [0,10+i]. ",
"def animate_example(i): ",
" x = np.linspace(0, 10+i, 1000) ",
" y = x*np.sin(np.power(x,0.8)) ",
" line.set_data(x, y) ",
" #We rescale the graph to the current system size: ",
" ax.relim() ",
" ax.autoscale_view(tight=False,scalex=True,scaley=True) ",
" return line, ",
" ",
"# call the animator. blit=True means only re-draw the parts that have changed. ",
"anim_example = animation.FuncAnimation(fig, animate_example, init_func=init, ",
" frames=np.arange(0, 250, 0.5), interval=20, blit=True) ",
" ",
" ",
"rc('animation', html='html5') ",
"HTML(anim_example.to_html5_video())"
]
},
{
cell_type: "markdown",
metadata: { },
source: [
"Create a movie in which you simulate a random walk and then zoom out with the scaling of Donsker's invariance principle."
]
},
{
cell_type: "code",
execution_count: 1,
metadata: { },
outputs: [ ],
source: [
"#TODO: your implementation goes here."
]
}
],
metadata: {
kernelspec: {
display_name: "Python 3",
language: "python",
name: "python3"
},
language_info: {
codemirror_mode: {
name: "ipython",
version: 3
},
file_extension: ".py",
mimetype: "text/x-python",
name: "python",
nbconvert_exporter: "python",
pygments_lexer: "ipython3",
version: "3.7.4"
}
},
nbformat: 4,
nbformat_minor: 2
}
